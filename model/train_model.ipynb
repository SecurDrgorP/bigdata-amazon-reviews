{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afabac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, when, isnan, lit\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer, NGram\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "070878eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/17 23:16:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema:\n",
      "root\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- overall: integer (nullable = true)\n",
      " |-- lemmatized_text: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n",
      "\n",
      "Nombre de lignes total: 10261\n",
      "\n",
      "Nombre de lignes total: 10261\n",
      "Valeurs nulles par colonne:\n",
      "Valeurs nulles par colonne:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---------------+-----+\n",
      "|reviewerID|overall|lemmatized_text|label|\n",
      "+----------+-------+---------------+-----+\n",
      "|         0|      0|              0|    0|\n",
      "+----------+-------+---------------+-----+\n",
      "\n",
      "\n",
      "Distribution des classes:\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|  467|\n",
      "|  1.0|  772|\n",
      "|  2.0| 9022|\n",
      "+-----+-----+\n",
      "\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|  467|\n",
      "|  1.0|  772|\n",
      "|  2.0| 9022|\n",
      "+-----+-----+\n",
      "\n",
      "\n",
      "Poids par classe:\n",
      "Classe 0.0: 21.9722\n",
      "Classe 1.0: 13.2915\n",
      "Classe 2.0: 1.1373\n",
      "\n",
      "Poids par classe:\n",
      "Classe 0.0: 21.9722\n",
      "Classe 1.0: 13.2915\n",
      "Classe 2.0: 1.1373\n",
      "\n",
      "Données d'entraînement: 8288 lignes\n",
      "\n",
      "Données d'entraînement: 8288 lignes\n",
      "Données de validation: 1012 lignes\n",
      "Données de validation: 1012 lignes\n",
      "Données de test: 961 lignes\n",
      "Données de test: 961 lignes\n"
     ]
    }
   ],
   "source": [
    "# Créer une session Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ReviewSentimentClassifier\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Configurer le niveau de log pour réduire les sorties\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "# Charger les données (prétraitées en pandas et sauvegardées en CSV)\n",
    "df = spark.read.csv(\"../data/cleaned_reviews.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Vérifier le schéma et les données nulles\n",
    "print(\"Schema:\")\n",
    "df.printSchema()\n",
    "\n",
    "# Vérification des valeurs nulles\n",
    "print(\"\\nNombre de lignes total:\", df.count())\n",
    "null_counts = df.select([count(when(col(c).isNull() | isnan(c), c)).alias(c) for c in df.columns])\n",
    "print(\"Valeurs nulles par colonne:\")\n",
    "null_counts.show()\n",
    "\n",
    "# Assurer que label est en format numérique et éliminer toute valeur aberrante\n",
    "df = df.filter((col(\"label\") == 0) | (col(\"label\") == 1) | (col(\"label\") == 2))\n",
    "df = df.withColumn(\"label\", col(\"label\").cast(\"double\"))\n",
    "\n",
    "# Remplacer les valeurs nulles dans la colonne \"lemmatized_text\" par une chaîne vide\n",
    "df = df.fillna({'lemmatized_text': ''})\n",
    "\n",
    "# Afficher des statistiques sur les classes\n",
    "print(\"\\nDistribution des classes:\")\n",
    "class_counts = df.groupBy(\"label\").count().orderBy(\"label\")\n",
    "class_counts.show()\n",
    "\n",
    "# Calculer les poids pour équilibrer les classes\n",
    "total = df.count()\n",
    "class_weights = class_counts.collect()\n",
    "weights_dict = {row[\"label\"]: total/row[\"count\"] for row in class_weights}\n",
    "print(\"\\nPoids par classe:\")\n",
    "for label, weight in weights_dict.items():\n",
    "    print(f\"Classe {label}: {weight:.4f}\")\n",
    "\n",
    "# Ajouter une colonne de poids pour l'algorithme de classification\n",
    "df = df.withColumn(\"weight\", \n",
    "    when(col(\"label\") == 0.0, lit(weights_dict[0.0]))\n",
    "    .when(col(\"label\") == 1.0, lit(weights_dict[1.0]))\n",
    "    .when(col(\"label\") == 2.0, lit(weights_dict[2.0]))\n",
    "    .otherwise(lit(1.0))\n",
    ")\n",
    "\n",
    "# Séparer les données en 80/10/10 (train/validation/test)\n",
    "# Premier split: 80% train, 20% temp\n",
    "train_df, temp_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "# Deuxième split: diviser les 20% restants en deux parts égales (validation/test)\n",
    "validation_df, test_df = temp_df.randomSplit([0.5, 0.5], seed=42)\n",
    "\n",
    "print(f\"\\nDonnées d'entraînement: {train_df.count()} lignes\")\n",
    "print(f\"Données de validation: {validation_df.count()} lignes\")\n",
    "print(f\"Données de test: {test_df.count()} lignes\")\n",
    "\n",
    "# Tokenisation\n",
    "tokenizer = Tokenizer(inputCol=\"lemmatized_text\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "\n",
    "# Ajouter extraction de bi-grammes pour capturer les phrases\n",
    "bigram = NGram(n=2, inputCol=\"filtered_words\", outputCol=\"bigrams\")\n",
    "\n",
    "# TF-IDF avec plus de features\n",
    "hashingTF = HashingTF(inputCol=\"bigrams\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "# Indexation de la classe avec gestion des valeurs nulles\n",
    "label_indexer = StringIndexer(\n",
    "    inputCol=\"label\", \n",
    "    outputCol=\"indexedLabel\", \n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "\n",
    "# Classifieur avec paramètres optimisés et utilisation des poids\n",
    "lr = LogisticRegression(\n",
    "    featuresCol=\"features\", \n",
    "    labelCol=\"indexedLabel\", \n",
    "    weightCol=\"weight\",\n",
    "    maxIter=20,\n",
    "    regParam=0.1,\n",
    "    elasticNetParam=0.5\n",
    ")\n",
    "\n",
    "# Pipeline complète\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, bigram, hashingTF, idf, label_indexer, lr])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97fd777b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entraînement du modèle en cours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation du modèle sur l'ensemble de validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Résultats de validation:\n",
      "F1-score (validation): 0.0033\n",
      "Précision (validation): 0.0415\n",
      "\n",
      "Matrice de confusion (validation):\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       2.0|   42|\n",
      "|  1.0|       2.0|   71|\n",
      "|  2.0|       2.0|  899|\n",
      "+-----+----------+-----+\n",
      "\n",
      "\n",
      "Évaluation finale sur l'ensemble de test...\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       2.0|   42|\n",
      "|  1.0|       2.0|   71|\n",
      "|  2.0|       2.0|  899|\n",
      "+-----+----------+-----+\n",
      "\n",
      "\n",
      "Évaluation finale sur l'ensemble de test...\n",
      "\n",
      "Exemples de prédictions (test):\n",
      "\n",
      "Exemples de prédictions (test):\n",
      "+------------------------------+-----+----------+------------------------------+\n",
      "|               lemmatized_text|label|prediction|                   probability|\n",
      "+------------------------------+-----+----------+------------------------------+\n",
      "|friend find love great soun...|  2.0|       2.0|[0.3316896008282762,0.33216...|\n",
      "|order new guitar strap flex...|  2.0|       2.0|[0.3316896008282762,0.33216...|\n",
      "|work advertise key stiff pa...|  0.0|       2.0|[0.3316896008282762,0.33216...|\n",
      "|wow think holy grail arrive...|  2.0|       2.0|[0.3316896008282762,0.33216...|\n",
      "|shop local music shop disco...|  2.0|       2.0|[0.3316896008282762,0.33216...|\n",
      "+------------------------------+-----+----------+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Distribution des prédictions (test):\n",
      "+------------------------------+-----+----------+------------------------------+\n",
      "|               lemmatized_text|label|prediction|                   probability|\n",
      "+------------------------------+-----+----------+------------------------------+\n",
      "|friend find love great soun...|  2.0|       2.0|[0.3316896008282762,0.33216...|\n",
      "|order new guitar strap flex...|  2.0|       2.0|[0.3316896008282762,0.33216...|\n",
      "|work advertise key stiff pa...|  0.0|       2.0|[0.3316896008282762,0.33216...|\n",
      "|wow think holy grail arrive...|  2.0|       2.0|[0.3316896008282762,0.33216...|\n",
      "|shop local music shop disco...|  2.0|       2.0|[0.3316896008282762,0.33216...|\n",
      "+------------------------------+-----+----------+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Distribution des prédictions (test):\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       2.0|  961|\n",
      "+----------+-----+\n",
      "\n",
      "\n",
      "Matrice de confusion (test):\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       2.0|  961|\n",
      "+----------+-----+\n",
      "\n",
      "\n",
      "Matrice de confusion (test):\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       2.0|   43|\n",
      "|  1.0|       2.0|   77|\n",
      "|  2.0|       2.0|  841|\n",
      "+-----+----------+-----+\n",
      "\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       2.0|   43|\n",
      "|  1.0|       2.0|   77|\n",
      "|  2.0|       2.0|  841|\n",
      "+-----+----------+-----+\n",
      "\n",
      "\n",
      "Résultats d'évaluation finaux (test):\n",
      "F1-score: 0.0038\n",
      "Précision: 0.0447\n",
      "Recall pondéré: 0.0447\n",
      "\n",
      "Résultats d'évaluation finaux (test):\n",
      "F1-score: 0.0038\n",
      "Précision: 0.0447\n",
      "Recall pondéré: 0.0447\n",
      "\n",
      "Modèle sauvegardé avec succès à: ../model/balanced_sentiment_model\n",
      "\n",
      "Modèle sauvegardé avec succès à: ../model/balanced_sentiment_model\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Entraîner le modèle sur les données d'entraînement\n",
    "    print(\"\\nEntraînement du modèle en cours...\")\n",
    "    model = pipeline.fit(train_df)\n",
    "    \n",
    "    # Évaluer sur les données de validation\n",
    "    print(\"Évaluation du modèle sur l'ensemble de validation...\")\n",
    "    val_predictions = model.transform(validation_df)\n",
    "    \n",
    "    # Calculer les métriques d'évaluation sur la validation\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"indexedLabel\", \n",
    "        predictionCol=\"prediction\", \n",
    "        metricName=\"f1\"\n",
    "    )\n",
    "    val_f1 = evaluator.evaluate(val_predictions)\n",
    "    \n",
    "    evaluator.setMetricName(\"accuracy\")\n",
    "    val_accuracy = evaluator.evaluate(val_predictions)\n",
    "    \n",
    "    print(f\"\\nRésultats de validation:\")\n",
    "    print(f\"F1-score (validation): {val_f1:.4f}\")\n",
    "    print(f\"Précision (validation): {val_accuracy:.4f}\")\n",
    "    \n",
    "    # Matrice de confusion sur la validation\n",
    "    print(\"\\nMatrice de confusion (validation):\")\n",
    "    val_predictions.groupBy(\"label\", \"prediction\").count().orderBy(\"label\", \"prediction\").show()\n",
    "    \n",
    "    # Évaluation finale sur l'ensemble de test\n",
    "    print(\"\\nÉvaluation finale sur l'ensemble de test...\")\n",
    "    test_predictions = model.transform(test_df)\n",
    "    \n",
    "    # Afficher quelques prédictions\n",
    "    print(\"\\nExemples de prédictions (test):\")\n",
    "    test_predictions.select(\"lemmatized_text\", \"label\", \"prediction\", \"probability\").show(5, truncate=30)\n",
    "    \n",
    "    # Afficher la distribution des prédictions sur l'ensemble de test\n",
    "    print(\"\\nDistribution des prédictions (test):\")\n",
    "    test_predictions.groupBy(\"prediction\").count().orderBy(\"prediction\").show()\n",
    "    \n",
    "    # Matrice de confusion simplifiée sur le test\n",
    "    print(\"\\nMatrice de confusion (test):\")\n",
    "    test_predictions.groupBy(\"label\", \"prediction\").count().orderBy(\"label\", \"prediction\").show()\n",
    "    \n",
    "    # Calculer les métriques finales sur l'ensemble de test\n",
    "    test_f1 = evaluator.setMetricName(\"f1\").evaluate(test_predictions)\n",
    "    test_accuracy = evaluator.setMetricName(\"accuracy\").evaluate(test_predictions)\n",
    "    test_recall = evaluator.setMetricName(\"weightedRecall\").evaluate(test_predictions)\n",
    "    \n",
    "    print(f\"\\nRésultats d'évaluation finaux (test):\")\n",
    "    print(f\"F1-score: {test_f1:.4f}\")\n",
    "    print(f\"Précision: {test_accuracy:.4f}\")\n",
    "    print(f\"Recall pondéré: {test_recall:.4f}\")\n",
    "    \n",
    "    # Sauvegarder le modèle\n",
    "    model_path = \"../model/balanced_sentiment_model\"\n",
    "    model.write().overwrite().save(model_path)\n",
    "    print(f\"\\nModèle sauvegardé avec succès à: {model_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nErreur pendant l'entraînement: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
