{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afabac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, when, isnan, lit\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer, NGram\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "070878eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/securdrgorp/Documents/MST/S2/BigData/project/bigdata-amazon-reviews/.VENV/lib64/python3.11/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/securdrgorp/Documents/MST/S2/BigData/project/bigdata-amazon-reviews/.VENV/lib64/python3.11/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib64/python3.11/socket.py\", line 718, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Créer une session Spark\u001b[39;00m\n\u001b[32m      2\u001b[39m spark = \u001b[43mSparkSession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mReviewSentimentClassifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mspark.driver.memory\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m4g\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Configurer le niveau de log pour réduire les sorties\u001b[39;00m\n\u001b[32m      8\u001b[39m spark.sparkContext.setLogLevel(\u001b[33m\"\u001b[39m\u001b[33mWARN\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MST/S2/BigData/project/bigdata-amazon-reviews/.VENV/lib64/python3.11/site-packages/pyspark/sql/session.py:497\u001b[39m, in \u001b[36mSparkSession.Builder.getOrCreate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    495\u001b[39m     sparkConf.set(key, value)\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m sc = \u001b[43mSparkContext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[32m    499\u001b[39m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[32m    500\u001b[39m session = SparkSession(sc, options=\u001b[38;5;28mself\u001b[39m._options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MST/S2/BigData/project/bigdata-amazon-reviews/.VENV/lib64/python3.11/site-packages/pyspark/context.py:515\u001b[39m, in \u001b[36mSparkContext.getOrCreate\u001b[39m\u001b[34m(cls, conf)\u001b[39m\n\u001b[32m    513\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext._lock:\n\u001b[32m    514\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext._active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    516\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext._active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    517\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext._active_spark_context\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MST/S2/BigData/project/bigdata-amazon-reviews/.VENV/lib64/python3.11/site-packages/pyspark/context.py:203\u001b[39m, in \u001b[36mSparkContext.__init__\u001b[39m\u001b[34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[39m\n\u001b[32m    201\u001b[39m SparkContext._ensure_initialized(\u001b[38;5;28mself\u001b[39m, gateway=gateway, conf=conf)\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m        \u001b[49m\u001b[43mappName\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m        \u001b[49m\u001b[43msparkHome\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpyFiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m        \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatchSize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjsc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprofiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[43mudf_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# If an error occurs, clean up in order to allow future SparkContext creation:\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;28mself\u001b[39m.stop()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MST/S2/BigData/project/bigdata-amazon-reviews/.VENV/lib64/python3.11/site-packages/pyspark/context.py:245\u001b[39m, in \u001b[36mSparkContext._do_init\u001b[39m\u001b[34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[39m\n\u001b[32m    243\u001b[39m     \u001b[38;5;28mself\u001b[39m._conf = conf\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m     \u001b[38;5;28mself\u001b[39m._conf = \u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_jvm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSparkContext\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jvm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m conf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    247\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m conf.getAll():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MST/S2/BigData/project/bigdata-amazon-reviews/.VENV/lib64/python3.11/site-packages/pyspark/conf.py:132\u001b[39m, in \u001b[36mSparkConf.__init__\u001b[39m\u001b[34m(self, loadDefaults, _jvm, _jconf)\u001b[39m\n\u001b[32m    128\u001b[39m _jvm = _jvm \u001b[38;5;129;01mor\u001b[39;00m SparkContext._jvm\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    131\u001b[39m     \u001b[38;5;66;03m# JVM is created, so create self._jconf directly through JVM\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     \u001b[38;5;28mself\u001b[39m._jconf = \u001b[43m_jvm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloadDefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m     \u001b[38;5;28mself\u001b[39m._conf = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    135\u001b[39m     \u001b[38;5;66;03m# JVM is not created, so store data in self._conf first\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MST/S2/BigData/project/bigdata-amazon-reviews/.VENV/lib64/python3.11/site-packages/py4j/java_gateway.py:1586\u001b[39m, in \u001b[36mJavaClass.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1578\u001b[39m args_command = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(\n\u001b[32m   1579\u001b[39m     [get_command_part(arg, \u001b[38;5;28mself\u001b[39m._pool) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m new_args])\n\u001b[32m   1581\u001b[39m command = proto.CONSTRUCTOR_COMMAND_NAME +\\\n\u001b[32m   1582\u001b[39m     \u001b[38;5;28mself\u001b[39m._command_header +\\\n\u001b[32m   1583\u001b[39m     args_command +\\\n\u001b[32m   1584\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m-> \u001b[39m\u001b[32m1586\u001b[39m answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_gateway_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1587\u001b[39m return_value = get_return_value(\n\u001b[32m   1588\u001b[39m     answer, \u001b[38;5;28mself\u001b[39m._gateway_client, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m._fqn)\n\u001b[32m   1590\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MST/S2/BigData/project/bigdata-amazon-reviews/.VENV/lib64/python3.11/site-packages/py4j/java_gateway.py:1038\u001b[39m, in \u001b[36mGatewayClient.send_command\u001b[39m\u001b[34m(self, command, retry, binary)\u001b[39m\n\u001b[32m   1036\u001b[39m connection = \u001b[38;5;28mself\u001b[39m._get_connection()\n\u001b[32m   1037\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1038\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[32m   1040\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m._create_connection_guard(connection)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MST/S2/BigData/project/bigdata-amazon-reviews/.VENV/lib64/python3.11/site-packages/py4j/clientserver.py:511\u001b[39m, in \u001b[36mClientServerConnection.send_command\u001b[39m\u001b[34m(self, command)\u001b[39m\n\u001b[32m    509\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    510\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m         answer = smart_decode(\u001b[38;5;28mself\u001b[39m.stream.readline()[:-\u001b[32m1\u001b[39m])\n\u001b[32m    512\u001b[39m         logger.debug(\u001b[33m\"\u001b[39m\u001b[33mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m\"\u001b[39m.format(answer))\n\u001b[32m    513\u001b[39m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[32m    514\u001b[39m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.11/socket.py:718\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m718\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    720\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Créer une session Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ReviewSentimentClassifier\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Configurer le niveau de log pour réduire les sorties\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "# Charger les données (prétraitées en pandas et sauvegardées en CSV)\n",
    "df = spark.read.csv(\"../data/cleaned_reviews.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Vérifier le schéma et les données nulles\n",
    "print(\"Schema:\")\n",
    "df.printSchema()\n",
    "\n",
    "# Vérification des valeurs nulles\n",
    "print(\"\\nNombre de lignes total:\", df.count())\n",
    "null_counts = df.select([count(when(col(c).isNull() | isnan(c), c)).alias(c) for c in df.columns])\n",
    "print(\"Valeurs nulles par colonne:\")\n",
    "null_counts.show()\n",
    "\n",
    "# Assurer que label est en format numérique et éliminer toute valeur aberrante\n",
    "df = df.filter((col(\"label\") == 0) | (col(\"label\") == 1) | (col(\"label\") == 2))\n",
    "df = df.withColumn(\"label\", col(\"label\").cast(\"double\"))\n",
    "\n",
    "# Remplacer les valeurs nulles dans la colonne \"lemmatized_text\" par une chaîne vide\n",
    "df = df.fillna({'lemmatized_text': ''})\n",
    "\n",
    "# Afficher des statistiques sur les classes\n",
    "print(\"\\nDistribution des classes:\")\n",
    "class_counts = df.groupBy(\"label\").count().orderBy(\"label\")\n",
    "class_counts.show()\n",
    "\n",
    "# Calculer les poids pour équilibrer les classes\n",
    "total = df.count()\n",
    "class_weights = class_counts.collect()\n",
    "weights_dict = {row[\"label\"]: total/row[\"count\"] for row in class_weights}\n",
    "print(\"\\nPoids par classe:\")\n",
    "for label, weight in weights_dict.items():\n",
    "    print(f\"Classe {label}: {weight:.4f}\")\n",
    "\n",
    "# Ajouter une colonne de poids pour l'algorithme de classification\n",
    "df = df.withColumn(\"weight\", \n",
    "    when(col(\"label\") == 0.0, lit(weights_dict[0.0]))\n",
    "    .when(col(\"label\") == 1.0, lit(weights_dict[1.0]))\n",
    "    .when(col(\"label\") == 2.0, lit(weights_dict[2.0]))\n",
    "    .otherwise(lit(1.0))\n",
    ")\n",
    "\n",
    "# Séparer les données en 80/10/10 (train/validation/test)\n",
    "# Premier split: 80% train, 20% temp\n",
    "train_df, temp_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "# Deuxième split: diviser les 20% restants en deux parts égales (validation/test)\n",
    "validation_df, test_df = temp_df.randomSplit([0.5, 0.5], seed=42)\n",
    "\n",
    "print(f\"\\nDonnées d'entraînement: {train_df.count()} lignes\")\n",
    "print(f\"Données de validation: {validation_df.count()} lignes\")\n",
    "print(f\"Données de test: {test_df.count()} lignes\")\n",
    "\n",
    "# Tokenisation\n",
    "tokenizer = Tokenizer(inputCol=\"lemmatized_text\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "\n",
    "# Ajouter extraction de bi-grammes pour capturer les phrases\n",
    "bigram = NGram(n=2, inputCol=\"filtered_words\", outputCol=\"bigrams\")\n",
    "\n",
    "# TF-IDF avec plus de features\n",
    "hashingTF = HashingTF(inputCol=\"bigrams\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "# Indexation de la classe avec gestion des valeurs nulles\n",
    "label_indexer = StringIndexer(\n",
    "    inputCol=\"label\", \n",
    "    outputCol=\"indexedLabel\", \n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "\n",
    "# Classifieur avec paramètres optimisés et utilisation des poids\n",
    "lr = LogisticRegression(\n",
    "    featuresCol=\"features\", \n",
    "    labelCol=\"indexedLabel\", \n",
    "    weightCol=\"weight\",\n",
    "    maxIter=20,\n",
    "    regParam=0.1,\n",
    "    elasticNetParam=0.5\n",
    ")\n",
    "\n",
    "# Pipeline complète\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, bigram, hashingTF, idf, label_indexer, lr])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fd777b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entraînement du modèle en cours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation du modèle sur l'ensemble de validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Résultats de validation:\n",
      "F1-score (validation): 0.0033\n",
      "Précision (validation): 0.0415\n",
      "\n",
      "Matrice de confusion (validation):\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       2.0|   42|\n",
      "|  1.0|       2.0|   71|\n",
      "|  2.0|       2.0|  899|\n",
      "+-----+----------+-----+\n",
      "\n",
      "\n",
      "Évaluation finale sur l'ensemble de test...\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       2.0|   42|\n",
      "|  1.0|       2.0|   71|\n",
      "|  2.0|       2.0|  899|\n",
      "+-----+----------+-----+\n",
      "\n",
      "\n",
      "Évaluation finale sur l'ensemble de test...\n",
      "\n",
      "Exemples de prédictions (test):\n",
      "\n",
      "Exemples de prédictions (test):\n",
      "+------------------------------+-----+----------+------------------------------+\n",
      "|               lemmatized_text|label|prediction|                   probability|\n",
      "+------------------------------+-----+----------+------------------------------+\n",
      "|friend find love great soun...|  2.0|       2.0|[0.3316896008282762,0.33216...|\n",
      "|order new guitar strap flex...|  2.0|       2.0|[0.3316896008282762,0.33216...|\n",
      "|work advertise key stiff pa...|  0.0|       2.0|[0.3316896008282762,0.33216...|\n",
      "|wow think holy grail arrive...|  2.0|       2.0|[0.3316896008282762,0.33216...|\n",
      "|shop local music shop disco...|  2.0|       2.0|[0.3316896008282762,0.33216...|\n",
      "+------------------------------+-----+----------+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Distribution des prédictions (test):\n",
      "+------------------------------+-----+----------+------------------------------+\n",
      "|               lemmatized_text|label|prediction|                   probability|\n",
      "+------------------------------+-----+----------+------------------------------+\n",
      "|friend find love great soun...|  2.0|       2.0|[0.3316896008282762,0.33216...|\n",
      "|order new guitar strap flex...|  2.0|       2.0|[0.3316896008282762,0.33216...|\n",
      "|work advertise key stiff pa...|  0.0|       2.0|[0.3316896008282762,0.33216...|\n",
      "|wow think holy grail arrive...|  2.0|       2.0|[0.3316896008282762,0.33216...|\n",
      "|shop local music shop disco...|  2.0|       2.0|[0.3316896008282762,0.33216...|\n",
      "+------------------------------+-----+----------+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Distribution des prédictions (test):\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       2.0|  961|\n",
      "+----------+-----+\n",
      "\n",
      "\n",
      "Matrice de confusion (test):\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       2.0|  961|\n",
      "+----------+-----+\n",
      "\n",
      "\n",
      "Matrice de confusion (test):\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       2.0|   43|\n",
      "|  1.0|       2.0|   77|\n",
      "|  2.0|       2.0|  841|\n",
      "+-----+----------+-----+\n",
      "\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       2.0|   43|\n",
      "|  1.0|       2.0|   77|\n",
      "|  2.0|       2.0|  841|\n",
      "+-----+----------+-----+\n",
      "\n",
      "\n",
      "Résultats d'évaluation finaux (test):\n",
      "F1-score: 0.0038\n",
      "Précision: 0.0447\n",
      "Recall pondéré: 0.0447\n",
      "\n",
      "Résultats d'évaluation finaux (test):\n",
      "F1-score: 0.0038\n",
      "Précision: 0.0447\n",
      "Recall pondéré: 0.0447\n",
      "\n",
      "Modèle sauvegardé avec succès à: ../model/balanced_sentiment_model\n",
      "\n",
      "Modèle sauvegardé avec succès à: ../model/balanced_sentiment_model\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Entraîner le modèle sur les données d'entraînement\n",
    "    print(\"\\nEntraînement du modèle en cours...\")\n",
    "    model = pipeline.fit(train_df)\n",
    "    \n",
    "    # Évaluer sur les données de validation\n",
    "    print(\"Évaluation du modèle sur l'ensemble de validation...\")\n",
    "    val_predictions = model.transform(validation_df)\n",
    "    \n",
    "    # Calculer les métriques d'évaluation sur la validation\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"indexedLabel\", \n",
    "        predictionCol=\"prediction\", \n",
    "        metricName=\"f1\"\n",
    "    )\n",
    "    val_f1 = evaluator.evaluate(val_predictions)\n",
    "    \n",
    "    evaluator.setMetricName(\"accuracy\")\n",
    "    val_accuracy = evaluator.evaluate(val_predictions)\n",
    "    \n",
    "    print(f\"\\nRésultats de validation:\")\n",
    "    print(f\"F1-score (validation): {val_f1:.4f}\")\n",
    "    print(f\"Précision (validation): {val_accuracy:.4f}\")\n",
    "    \n",
    "    # Matrice de confusion sur la validation\n",
    "    print(\"\\nMatrice de confusion (validation):\")\n",
    "    val_predictions.groupBy(\"label\", \"prediction\").count().orderBy(\"label\", \"prediction\").show()\n",
    "    \n",
    "    # Évaluation finale sur l'ensemble de test\n",
    "    print(\"\\nÉvaluation finale sur l'ensemble de test...\")\n",
    "    test_predictions = model.transform(test_df)\n",
    "    \n",
    "    # Afficher quelques prédictions\n",
    "    print(\"\\nExemples de prédictions (test):\")\n",
    "    test_predictions.select(\"lemmatized_text\", \"label\", \"prediction\", \"probability\").show(5, truncate=30)\n",
    "    \n",
    "    # Afficher la distribution des prédictions sur l'ensemble de test\n",
    "    print(\"\\nDistribution des prédictions (test):\")\n",
    "    test_predictions.groupBy(\"prediction\").count().orderBy(\"prediction\").show()\n",
    "    \n",
    "    # Matrice de confusion simplifiée sur le test\n",
    "    print(\"\\nMatrice de confusion (test):\")\n",
    "    test_predictions.groupBy(\"label\", \"prediction\").count().orderBy(\"label\", \"prediction\").show()\n",
    "    \n",
    "    # Calculer les métriques finales sur l'ensemble de test\n",
    "    test_f1 = evaluator.setMetricName(\"f1\").evaluate(test_predictions)\n",
    "    test_accuracy = evaluator.setMetricName(\"accuracy\").evaluate(test_predictions)\n",
    "    test_recall = evaluator.setMetricName(\"weightedRecall\").evaluate(test_predictions)\n",
    "    \n",
    "    print(f\"\\nRésultats d'évaluation finaux (test):\")\n",
    "    print(f\"F1-score: {test_f1:.4f}\")\n",
    "    print(f\"Précision: {test_accuracy:.4f}\")\n",
    "    print(f\"Recall pondéré: {test_recall:.4f}\")\n",
    "    \n",
    "    # Sauvegarder le modèle\n",
    "    model_path = \"../model/balanced_sentiment_model\"\n",
    "    model.write().overwrite().save(model_path)\n",
    "    print(f\"\\nModèle sauvegardé avec succès à: {model_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nErreur pendant l'entraînement: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
